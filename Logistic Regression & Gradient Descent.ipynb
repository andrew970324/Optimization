{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b314a27f",
   "metadata": {},
   "source": [
    "# Logistic Regression & Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845291ec",
   "metadata": {},
   "source": [
    "## Pre-processing Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145631c",
   "metadata": {},
   "source": [
    "Build out necessary functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aaa4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient function\n",
    "def grad(w, x, y):\n",
    "    gradient = np.zeros(len(w))\n",
    "    for i in range(len(y)):\n",
    "        dot_prod = np.dot(w.T,x.iloc[i,:])\n",
    "        gradient += (1/len(y)) * (1/ (1 + np.exp(-dot_prod)) - y[i]) * x.iloc[i,:] \n",
    "    return gradient\n",
    "\n",
    "# Likelihood function\n",
    "def fval(w, x, y):\n",
    "    return none\n",
    "\n",
    "# Gradient norm function\n",
    "def gradnorm(w, x, y):\n",
    "    norm = np.linalg.norm(grad(w, x, y))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee0c0d",
   "metadata": {},
   "source": [
    "## Question 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6856797e",
   "metadata": {},
   "source": [
    "First, let's load the necessary libraries and also our training/test sets into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8bf5e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Load the training and test datasets\n",
    "df_train = pd.read_csv('LRTrain.csv')\n",
    "df_test = pd.read_csv('LRTest.csv')\n",
    "\n",
    "x_train = df_train.iloc[:, :30]\n",
    "y_train = df_train.iloc[:, 30]\n",
    "\n",
    "x_test = df_test.iloc[:, :30]\n",
    "y_test = df_test.iloc[:, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d02bda",
   "metadata": {},
   "source": [
    "Next, let's create an array of weights with values of 0 and then use our gradient function to test how it works initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91ee8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                 0.458658\n",
       "texture_mean                1.691417\n",
       "perimeter_mean              2.375267\n",
       "area_mean                 -40.365500\n",
       "smoothness_mean             0.008910\n",
       "compactness_mean           -0.002134\n",
       "concavity_mean             -0.015543\n",
       "concave points_mean        -0.008387\n",
       "symmetry_mean               0.017676\n",
       "fractal_dimension_mean      0.007700\n",
       "radius_se                  -0.025793\n",
       "texture_se                  0.173138\n",
       "perimeter_se               -0.193368\n",
       "area_se                    -6.799432\n",
       "smoothness_se               0.000921\n",
       "compactness_se              0.000944\n",
       "concavity_se                0.000370\n",
       "concave points_se           0.000161\n",
       "symmetry_se                 0.002530\n",
       "fractal_dimension_se        0.000454\n",
       "radius_worst                0.140833\n",
       "texture_worst               2.067767\n",
       "perimeter_worst             0.150683\n",
       "area_worst                -94.503167\n",
       "smoothness_worst            0.011041\n",
       "compactness_worst          -0.011923\n",
       "concavity_worst            -0.031749\n",
       "concave points_worst       -0.011190\n",
       "symmetry_worst              0.022928\n",
       "fractal_dimension_worst     0.007683\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros(df_train.shape[1] - 1)\n",
    "grad(w, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c200f6",
   "metadata": {},
   "source": [
    "Now that we see that our gradient function works properly, let's do some experimentation with a for loop specifying step size and iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6d463b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius_mean               -0.006887\n",
      "texture_mean              -0.012517\n",
      "perimeter_mean            -0.039848\n",
      "area_mean                 -0.017586\n",
      "smoothness_mean           -0.000067\n",
      "compactness_mean           0.000029\n",
      "concavity_mean             0.000125\n",
      "concave points_mean        0.000055\n",
      "symmetry_mean             -0.000136\n",
      "fractal_dimension_mean    -0.000055\n",
      "radius_se                 -0.000083\n",
      "texture_se                -0.001038\n",
      "perimeter_se              -0.000134\n",
      "area_se                    0.008291\n",
      "smoothness_se             -0.000004\n",
      "compactness_se             0.000006\n",
      "concavity_se               0.000013\n",
      "concave points_se          0.000003\n",
      "symmetry_se               -0.000013\n",
      "fractal_dimension_se      -0.000002\n",
      "radius_worst              -0.007117\n",
      "texture_worst             -0.016294\n",
      "perimeter_worst           -0.038313\n",
      "area_worst                 0.023714\n",
      "smoothness_worst          -0.000085\n",
      "compactness_worst          0.000138\n",
      "concavity_worst            0.000262\n",
      "concave points_worst       0.000070\n",
      "symmetry_worst            -0.000185\n",
      "fractal_dimension_worst   -0.000054\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.00001\n",
    "iter_t = 2000\n",
    "\n",
    "w = np.zeros(df_train.shape[1] - 1)\n",
    "\n",
    "for i in range(iter_t):\n",
    "    w = w - step_size * grad(w, x_train, y_train)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00028ee3",
   "metadata": {},
   "source": [
    "Experimentation with a while loop using norm function and epsilon value of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88a356f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius_mean               -0.007451\n",
      "texture_mean              -0.013128\n",
      "perimeter_mean            -0.042786\n",
      "area_mean                 -0.017743\n",
      "smoothness_mean           -0.000070\n",
      "compactness_mean           0.000041\n",
      "concavity_mean             0.000148\n",
      "concave points_mean        0.000064\n",
      "symmetry_mean             -0.000144\n",
      "fractal_dimension_mean    -0.000059\n",
      "radius_se                 -0.000088\n",
      "texture_se                -0.001095\n",
      "perimeter_se              -0.000081\n",
      "area_se                    0.009141\n",
      "smoothness_se             -0.000004\n",
      "compactness_se             0.000010\n",
      "concavity_se               0.000018\n",
      "concave points_se          0.000004\n",
      "symmetry_se               -0.000013\n",
      "fractal_dimension_se      -0.000002\n",
      "radius_worst              -0.007712\n",
      "texture_worst             -0.017034\n",
      "perimeter_worst           -0.040814\n",
      "area_worst                 0.024539\n",
      "smoothness_worst          -0.000088\n",
      "compactness_worst          0.000181\n",
      "concavity_worst            0.000319\n",
      "concave points_worst       0.000086\n",
      "symmetry_worst            -0.000193\n",
      "fractal_dimension_worst   -0.000055\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "w_1 = np.zeros(df_train.shape[1] - 1)\n",
    "grad1 = 1000000\n",
    "while grad1 > 1:\n",
    "    w_1 = w_1 - step_size * grad(w_1, x_train, y_train)\n",
    "    grad1 = abs(gradnorm(w_1, x_train, y_train))\n",
    "\n",
    "print(w_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b19dee",
   "metadata": {},
   "source": [
    "## Question 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810c399",
   "metadata": {},
   "source": [
    "Build out functions for true positive rate (TPR) and false positive rate (FPR) below. Once we have functions for TPR and FPR built, we can calculate true negative rate (TNR) and false negative rate (FNR) thereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027d89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive rate\n",
    "def TPR(true_p, total_p):\n",
    "    return true_p/total_p\n",
    "\n",
    "# False positive rate\n",
    "def FPR(false_p, total_n):\n",
    "    return false_p/total_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c438d",
   "metadata": {},
   "source": [
    "Build out empty dataframe first to report the performance of our classifier below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0e4bad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.DataFrame(columns = ['TPR', 'FPR', 'TNR', 'FNR'], \n",
    "                   index = ['0.0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1.0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f252f9",
   "metadata": {},
   "source": [
    "Obtain actual number of positives and number of negatives from our test set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5371d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of positives: 98\n",
      "Actual number of negatives: 171\n"
     ]
    }
   ],
   "source": [
    "# Actual number of positives\n",
    "total_p_test = y_test[y_test == 1].count()\n",
    "\n",
    "# Actual number of negatives\n",
    "total_n_test = y_test[y_test == 0].count()\n",
    "\n",
    "print(\"Actual number of positives:\", total_p_test)\n",
    "print(\"Actual number of negatives:\", total_n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf284fb",
   "metadata": {},
   "source": [
    "After experimenting with specifying step size & iterations against using a termination criteria related to the norm of the gradient, let's use the optimal value `w_1` we obtained from our while loop that had the termination criteria to calculate our performance metric for the different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "afaa2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "performance_t = np.zeros((len(y_test), len(t_values)))\n",
    "\n",
    "for t in range(len(t_values)):\n",
    "    for i in range(len(y_test)):\n",
    "        pred = 1/(1 + np.exp(np.dot(-w_1.T,x_test.iloc[i,:])))\n",
    "        if pred > t_values[t]:\n",
    "            performance_t[i,t] += 1\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d6322",
   "metadata": {},
   "source": [
    "Let's create our dataframe comparing our actual `y_test` values against the values we achieved at our different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9d76f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate arrays of y values predicted for each threshold\n",
    "t_0 = performance_t[:,0]\n",
    "t_1 = performance_t[:,1]\n",
    "t_2 = performance_t[:,2]\n",
    "t_3 = performance_t[:,3]\n",
    "t_4 = performance_t[:,4]\n",
    "t_5 = performance_t[:,5]\n",
    "t_6 = performance_t[:,6]\n",
    "t_7 = performance_t[:,7]\n",
    "t_8 = performance_t[:,8]\n",
    "t_9 = performance_t[:,9]\n",
    "t_10 = performance_t[:,10]\n",
    "\n",
    "# Add each array above to a dataframe where we can compare predicted y values against actual y_test values\n",
    "y_test_comp = y_test.to_frame()\n",
    "y_test_comp['t=0'] = t_0\n",
    "y_test_comp['t=0.1'] = t_1\n",
    "y_test_comp['t=0.2'] = t_2\n",
    "y_test_comp['t=0.3'] = t_3\n",
    "y_test_comp['t=0.4'] = t_4\n",
    "y_test_comp['t=0.5'] = t_5\n",
    "y_test_comp['t=0.6'] = t_6\n",
    "y_test_comp['t=0.7'] = t_7\n",
    "y_test_comp['t=0.8'] = t_8\n",
    "y_test_comp['t=0.9'] = t_9\n",
    "y_test_comp['t=1.0'] = t_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce2d8b",
   "metadata": {},
   "source": [
    "Now, let's iterate through each column and compare our predicted values for each threshold with the actual `y_test` diagnosis values. Then, we will obtain numbers for our true positives and false positives at each threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f15f9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for number of true positives and false positives for each threshold below\n",
    "true_pos = np.zeros(11)\n",
    "false_pos = np.zeros(11)\n",
    "\n",
    "# Iteration through each row for each threshold value\n",
    "for j in range(10):\n",
    "    for i in y_test_comp.index:\n",
    "        if y_test_comp['diagnosis'][i] == 1:\n",
    "            if y_test_comp['diagnosis'][i] == y_test_comp.iloc[i][j+1]:\n",
    "                true_pos[j] += 1\n",
    "            else:\n",
    "                continue\n",
    "        if y_test_comp['diagnosis'][i] == 0:\n",
    "            if y_test_comp['diagnosis'][i] != y_test_comp.iloc[i][j+1]:\n",
    "                false_pos[j] += 1\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a840b7",
   "metadata": {},
   "source": [
    "Finally, let's use the number of true positives and false positives we found to calculate TPR, FPR, TNR, and FPR. Then, we can update these calculated metrics in our `df_t` dataframe we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "01babd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR\n",
    "for i in range(11):\n",
    "    df_t.iloc[[i],[0]] = TPR(true_pos[i], total_p_test)\n",
    "\n",
    "# FPR\n",
    "for i in range(11):\n",
    "    df_t.iloc[[i],[1]] = FPR(false_pos[i], total_n_test)\n",
    "\n",
    "# TNR\n",
    "for i in range(11):\n",
    "    df_t.iloc[[i],[2]] = 1 - df_t.iloc[[i],[1]]\n",
    "\n",
    "# FNR    \n",
    "for i in range(11):\n",
    "    df_t.iloc[[i],[3]] = 1 - df_t.iloc[[i],[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e8fa5e",
   "metadata": {},
   "source": [
    "Below, we can see the performance of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "76900ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.091837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.05848</td>\n",
       "      <td>0.94152</td>\n",
       "      <td>0.112245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.02924</td>\n",
       "      <td>0.97076</td>\n",
       "      <td>0.153061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.265306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR       FPR       TNR       FNR\n",
       "0.0       1.0       1.0       0.0       0.0\n",
       "0.1  0.979592  0.538012  0.461988  0.020408\n",
       "0.2  0.959184  0.192982  0.807018  0.040816\n",
       "0.3  0.908163  0.105263  0.894737  0.091837\n",
       "0.4  0.887755   0.05848   0.94152  0.112245\n",
       "0.5  0.857143  0.040936  0.959064  0.142857\n",
       "0.6  0.846939   0.02924   0.97076  0.153061\n",
       "0.7  0.785714  0.011696  0.988304  0.214286\n",
       "0.8  0.734694  0.005848  0.994152  0.265306\n",
       "0.9  0.714286  0.005848  0.994152  0.285714\n",
       "1.0       0.0       0.0       1.0       1.0"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
